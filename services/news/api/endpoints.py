"""
Endpoints API espec铆ficos del servicio de noticias.
Extra铆dos desde app/api/endpoints.py para funcionalidad de noticias.
"""
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from shared.services.logging_config import get_logger
from shared.database import session
from services.news.schedulers.news_scheduler import get_news_scheduler
from services.news.services import reddit_service

logger = get_logger(__name__)

# Crear el router espec铆fico para noticias
news_router = APIRouter(prefix="/news", tags=["News"])

# --- Dependencia para la sesi贸n de DB ---
def get_db():
    db = session.SessionLocal()
    try:
        yield db
    finally:
        db.close()

# --- Endpoints espec铆ficos de noticias ---
@news_router.post("/trigger-collection")
def trigger_collection(db: Session = Depends(get_db)):
    """
    Endpoint para disparar manualmente la recolecci贸n de noticias desde Reddit.
    til para pruebas y debugging.
    """
    logger.info(" Disparando la recolecci贸n de noticias desde Reddit manualmente...")
    result = reddit_service.fetch_and_store_posts(db)
    
    if result["success"]:
        return {
            "status": "success",
            "message": result["message"],
            "new_posts": result.get("new_posts", 0),
            "total_posts": result.get("total_posts", 0)
        }
    else:
        # Retorna error HTTP apropiado pero sin romper la API
        return {
            "status": "error",
            "message": f"Error en la recolecci贸n desde Reddit: {result['error']}",
            "error_details": result["error"]
        }

@news_router.get("/status")
def news_status():
    """
    Endpoint de diagn贸stico para verificar el estado del scheduler de noticias.
    Muestra informaci贸n sobre las tareas de recolecci贸n y an谩lisis de sentimientos.
    """
    try:
        scheduler = get_news_scheduler()
        
        if not scheduler or not scheduler.running:
            return {
                "status": "scheduler_stopped",
                "message": "El scheduler de noticias no est谩 ejecut谩ndose",
                "jobs": []
            }
        
        jobs_info = []
        for job in scheduler.get_jobs():
            job_data = {
                "id": job.id,
                "name": job.name or job.func.__name__ if hasattr(job.func, '__name__') else str(job.func),
                "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None
            }
            jobs_info.append(job_data)
        
        return {
            "status": "scheduler_running",
            "message": f"Scheduler de noticias activo con {len(jobs_info)} tareas programadas",
            "jobs": jobs_info
        }
    
    except Exception as e:
        return {
            "status": "error",
            "message": f"Error al obtener el estado del scheduler de noticias: {str(e)}",
            "jobs": []
        }

@news_router.get("/")
def news_service_info():
    """
    Informaci贸n general del servicio de noticias.
    """
    return {
        "service": "News Service",
        "description": "Recopilaci贸n de noticias de Reddit y an谩lisis de sentimientos",
        "features": [
            "Recopilaci贸n autom谩tica cada hora desde Reddit",
            "An谩lisis de sentimientos cada 4 horas",
            "Filtrado por dominios de noticias confiables",
            "Eliminaci贸n de duplicados"
        ],
        "status": "active"
    } 