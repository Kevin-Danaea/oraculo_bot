"""
Router para integraci√≥n con el servicio Cerebro
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from shared.services.logging_config import get_logger
from services.grid.schedulers.multibot_scheduler import (
    get_multibot_scheduler
)
from services.grid.core.cerebro_integration import cerebro_client
from services.grid.core.trading_mode_manager import trading_mode_manager
from services.grid.data.config_repository import get_all_active_configs, get_all_active_configs_for_user
from datetime import datetime

logger = get_logger(__name__)
router = APIRouter(prefix="/cerebro", tags=["Cerebro"])

class DecisionCerebro(BaseModel):
    """Modelo para recibir decisiones del Cerebro"""
    par: str
    decision: str  # OPERAR_GRID o PAUSAR_GRID
    adx_valor: float
    volatilidad_valor: float
    sentiment_promedio: float
    timestamp: str
    razon: str = ""  # Campo opcional para la raz√≥n
    fuente: str = "cerebro"  # Campo opcional para la fuente

@router.post("/decision")
async def recibir_decision_cerebro(decision: DecisionCerebro):
    """
    Endpoint para recibir decisiones autom√°ticas del Cerebro.
    SOLO REGISTRA LA DECISI√ìN. El scheduler la aplicar√° en su ciclo.
    """
    try:
        # Actualizar estado global para monitoreo por /status
        cerebro_client.estado_cerebro.update({
            "decision": decision.decision,
            "ultima_actualizacion": decision.timestamp,
            "fuente": "cerebro_notificacion_automatica"
        })
        
        logger.info(f"üß† Decisi√≥n del Cerebro RECIBIDA y REGISTRADA: {decision.decision} para {decision.par}")
        logger.info(f"   - Raz√≥n: {decision.razon}")
        logger.info(f"   - El scheduler la aplicar√° en el pr√≥ximo ciclo de verificaci√≥n.")

        # La decisi√≥n ya fue guardada en la BD por el servicio Cerebro.
        # Este endpoint solo acusa recibo. No ejecuta ninguna acci√≥n para
        # evitar condiciones de carrera con el inicio/parada manual.
        # El scheduler, en su ciclo, se encargar√° de aplicar los cambios.
        
        return {
            "status": "success",
            "message": f"Decisi√≥n '{decision.decision}' para {decision.par} registrada. El scheduler actuar√° en su pr√≥ximo ciclo.",
            "action_taken": "none",
            "timestamp": decision.timestamp
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error procesando recepci√≥n de decisi√≥n del Cerebro: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/estado")
def obtener_estado_cerebro():
    """
    Obtiene el estado actual de la decisi√≥n del Cerebro
    """
    config = trading_mode_manager.get_config()
    
    return {
        "estado_cerebro": cerebro_client.estado_cerebro,
        "modo_trading": config["modo"],
        "timestamp": cerebro_client.estado_cerebro.get("ultima_actualizacion"),
        "status": "active"
    }

@router.get("/batch/analysis")
async def get_batch_analysis():
    """
    Endpoint para obtener an√°lisis batch del cerebro desde el Grid.
    Mejora la eficiencia al obtener todas las decisiones de una vez.
    
    Returns:
        An√°lisis completo de todos los pares desde el cerebro
    """
    try:
        logger.info("üöÄ ========== SOLICITUD DE AN√ÅLISIS BATCH DESDE GRID ==========")
        
        # Consultar an√°lisis batch del cerebro
        decisiones_batch = await cerebro_client.consultar_y_procesar_batch()
        
        if not decisiones_batch:
            raise HTTPException(
                status_code=500,
                detail="No se pudo obtener an√°lisis batch del cerebro"
            )
        
        # Preparar respuesta
        response = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "total_pairs": len(decisiones_batch),
            "pairs_analyzed": list(decisiones_batch.keys()),
            "decisions": decisiones_batch,
            "summary": {
                "OPERAR_GRID": 0,
                "PAUSAR_GRID": 0,
                "ERROR": 0
            }
        }
        
        # Calcular resumen
        for par, decision_data in decisiones_batch.items():
            if decision_data.get('success', False):
                decision = decision_data.get('decision', 'ERROR')
                response["summary"][decision] += 1
            else:
                response["summary"]["ERROR"] += 1
        
        logger.info(f"‚úÖ An√°lisis batch completado desde Grid: {response['summary']}")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis batch desde Grid: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error en an√°lisis batch: {str(e)}"
        ) 